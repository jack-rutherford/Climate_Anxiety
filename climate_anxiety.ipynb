{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Anxiety in Youth and Perception of Government\n",
    "## Question/Hypothesis: \n",
    "**Response Variable:** Q1 - I am worried that climate change threatens people and the planet.\n",
    "\n",
    "**Predictors:** language, country, region, age, sex, Q2-Q8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "from scipy.stats import randint\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_spss('Climate Anxiety-3.SAV')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns, len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Q1'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nan or 'Prefer not to say' values in the Q1 column\n",
    "df['Q1'].isna().sum(), df['Q1'].str.contains('Prefer not to say').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Q1'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AgeGender'].unique(), len(df['AgeGender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of men and women in the dataset\n",
    "df['AgeGender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace columns with more descriptive names\n",
    "The original convention used to describe the columns is not very descriptive. We will replace the column names with more descriptive names.\n",
    "\n",
    "The new convention will be the Question number (Q1, Q2, Q3, etc.) followed by a descriptive word from the poll associated with that question/subquestion.\n",
    "\n",
    "For example, Q2 is \"Does climate change make you feel any of the following?\" with sad being one of the options, and the responses being yes, no, and prefer not to say. The new column name will be Q2_sad and will contain the values yes, not, or nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Repondent_Serial', 'language', 'country', 'age', 'sex', 'country:region', \n",
    "           'Q1', \n",
    "           'Q2_sad', 'Q2_helpless', 'Q2_anxious', 'Q2_afraid', 'Q2_optimistic',\n",
    "           'Q2_angry', 'Q2_guilty', 'Q2_ashamed', 'Q2_hurt', 'Q2_depressed', 'Q2_despair',\n",
    "           'Q2_grief', 'Q2_powerless', 'Q2_indifferent', \n",
    "           'Q3', \n",
    "           'Q4_hesitant', 'Q4_doomed','Q4_frightening', 'Q4_oppotunities', 'Q4_threatened', 'Q4_destroyed', 'Q4_failed',\n",
    "           'Q5', \n",
    "           'Q6', \n",
    "           'Q7_concerns', 'Q7_catastrophe', 'Q7_distress', 'Q7_science', 'Q7_generations', 'Q7_trusted', 'Q7_effectiveness', 'Q7_failing', 'Q7_betraying',\n",
    "           'Q8_anguished', 'Q8_abandoned', 'Q8_afraid', 'Q8_hopeful', 'Q8_angry', 'Q8_valued', 'Q8_ashamed', 'Q8_belittled', 'Q8_protected',\n",
    "           'yyyymmdd','AgeGender', \n",
    "           'regionAustralia', 'regionUS', 'regionUK', 'regionIndia', 'regionNigeria', 'regionPhilippines', 'regionFinland', 'regionPortugal', 'regionBrazil', 'regionFrance', 'weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = columns\n",
    "df.columns, len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all of the region columns\n",
    "# Make a new region column that splits the country:region column by ':'\n",
    "df['region'] = df['country:region'].str.split(':').str[1]\n",
    "df = df.drop(columns=['regionAustralia', 'regionUS', 'regionUK', 'regionIndia', 'regionNigeria', 'regionPhilippines', 'regionFinland', 'regionPortugal', 'regionBrazil', 'regionFrance'])\n",
    "df.columns, len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: Drop all rows with missing response variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Q1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['extremely', 'very', 'moderately', 'a little', 'not worried']\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Sort by the value counts of the Q1 column\n",
    "# sns.countplot(x='Q1', data=df, hue='Q1', palette='viridis', legend=False, order=df['Q1'].value_counts().sort_values(ascending=False).index)\n",
    "sns.countplot(x='Q1', data=df, hue='Q1', palette='viridis', legend=False, order=order)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Q1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='region', data=df, hue='region', palette='viridis', legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all rows with no null values\n",
    "df[df.notnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Limit the number of unique values in the 'sex' column to a manageable number\n",
    "top_sex = df['sex'].value_counts().nlargest(10).index\n",
    "df_limited = df[df['sex'].isin(top_sex)]\n",
    "\n",
    "sns.countplot(x='sex', data=df_limited, hue='sex', palette='viridis', legend=False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('sex')\n",
    "\n",
    "for i, sex in enumerate(df_limited['sex'].unique()):\n",
    "    sex_count = df_limited['sex'].value_counts()[sex]\n",
    "    plt.text(i, sex_count, f'{sex_count}', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: Show most populus regions in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Limit the number of unique values in the 'region' column to a manageable number\n",
    "top_region = df['region'].value_counts().nlargest(10).index\n",
    "df_limited = df[df['region'].isin(top_region)]\n",
    "\n",
    "sns.countplot(x='region', data=df_limited, hue='region', palette='viridis', legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('region')\n",
    "\n",
    "for i, region in enumerate(df_limited['region'].unique()):\n",
    "    region_count = df_limited['region'].value_counts()[region]\n",
    "    plt.text(i, region_count, f'{region_count}', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unused variables \n",
    "X = df.drop(columns=['Repondent_Serial', 'language', 'country', 'country:region', 'yyyymmdd', 'AgeGender', 'region', 'weight']) # not the same as the X used in data analysis\n",
    "\n",
    "for column in X.columns:\n",
    "    summary = X[column].describe()\n",
    "\n",
    "    print(f'{column}') \n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the sex column to be binary (0 or 1)\n",
    "X['sex'] = [0 if sex == 'man' else 1 for sex in df['sex']]\n",
    "\n",
    "#change yes/no questions to be binary (0 = no, 1 = yes?)\n",
    "for column in X.columns:\n",
    "    if X[column].unique().size == 2:\n",
    "        X[column] = [0 if value == X[column].unique()[0] else 1 for value in X[column]]\n",
    "    else:\n",
    "        X[column] = X[column].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "for column in X.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.countplot(x=column, data=df, hue=column, palette='viridis', legend=False)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f'Count Plot of {column}')\n",
    "\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if not pd.isna(height):  \n",
    "            ax.text(\n",
    "                x=p.get_x() + p.get_width() / 2,  \n",
    "                y=height,  \n",
    "                s=int(height),  \n",
    "                ha='center', \n",
    "                va='bottom'   \n",
    "            )\n",
    "    \n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations\n",
    "\n",
    "correlations = X.corr()\n",
    "q1_correlations = correlations['Q1']\n",
    "print(q1_correlations.sort_values(ascending=True))\n",
    "\n",
    "# Individually, none of the variables that we are using seem to have any practically significant correlations with Q1. \n",
    "# The variable with the Q1 correlation with the largest magnitude is Q2_afraid, with a correlaiton of .082."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "Try data anaylsis with different models. Try with and without non-numeric columns (like language, country)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models without non-numeric columns:\n",
    "#### Variables + Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Repondent_Serial', 'language', 'country', 'country:region', 'yyyymmdd', 'AgeGender', 'region', 'Q1'])\n",
    "y = df['Q1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = X['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the sex column to be binary (0 or 1)\n",
    "X['sex'] = [0 if sex == 'man' else 1 for sex in df['sex']]\n",
    "\n",
    "#change yes/no questions to be binary (0 = no, 1 = yes?)\n",
    "for column in X.columns:\n",
    "    if X[column].unique().size == 2:\n",
    "        X[column] = [0 if value == X[column].unique()[0] else 1 for value in X[column]]\n",
    "    else:\n",
    "        X[column] = X[column].astype('category').cat.codes\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after = X['sex'].value_counts()\n",
    "before.values == after.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'extremely': 4,\n",
    "    'very': 3,\n",
    "    'moderately': 2,\n",
    "    'a little': 1,\n",
    "    'not worried': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Q6', 'Q8_anguished', 'Q8_abandoned', 'Q8_afraid', 'Q8_hopeful',\n",
       "        'Q8_angry', 'Q8_valued', 'Q8_ashamed', 'Q8_belittled', 'Q8_protected'],\n",
       "       dtype='object'),\n",
       " 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# All columns that start with Q6 or Q8 will be in df_ordinal\n",
    "X_ordinal = X.filter(regex='Q6|Q8')\n",
    "X_ordinal.columns, len(X_ordinal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Q2_sad', 'Q2_helpless', 'Q2_anxious', 'Q2_afraid', 'Q2_optimistic',\n",
       "        'Q2_angry', 'Q2_guilty', 'Q2_ashamed', 'Q2_hurt', 'Q2_depressed',\n",
       "        'Q2_despair', 'Q2_grief', 'Q2_powerless', 'Q2_indifferent', 'Q3',\n",
       "        'Q4_hesitant', 'Q4_doomed', 'Q4_frightening', 'Q4_oppotunities',\n",
       "        'Q4_threatened', 'Q4_destroyed', 'Q4_failed', 'Q5', 'Q7_concerns',\n",
       "        'Q7_catastrophe', 'Q7_distress', 'Q7_science', 'Q7_generations',\n",
       "        'Q7_trusted', 'Q7_effectiveness', 'Q7_failing', 'Q7_betraying'],\n",
       "       dtype='object'),\n",
       " 32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_nominal = X.filter(regex='Q2|Q3|Q4|Q5|Q7')\n",
    "X_nominal.columns, len(X_nominal.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Oridnal/Nominal Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = rf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_RF)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the first three decision trees from the forest\n",
    "\n",
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model!\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "print('Best hyperparameters:',  rand_search.best_params_)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(y_pred == y_test), np.mean(y_pred != y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest (Bagging Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(min_samples_leaf=7) #min_samples_split=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_model = BaggingClassifier(estimator=tree, n_estimators=100, \n",
    "                                  bootstrap=True,\n",
    "                                  bootstrap_features=True,     # RF\n",
    "                                  oob_score=True,                     \n",
    "                                  random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print('oob score =', ens_model.oob_score_)\n",
    "\n",
    "pred = ens_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    " \n",
    "gbc.fit(X_train, y_train)\n",
    " \n",
    "y_pred_gbc = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_gbc = confusion_matrix(y_test, y_pred_gbc)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_gbc).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_importances_gbc = gbc.feature_importances_\n",
    "indices_gbc = np.argsort(feature_importances_gbc)[::-1]\n",
    "\n",
    "feature_names = df.columns\n",
    "top_feature_names = feature_names[indices_gbc[:3]]\n",
    "top_feature_importances = feature_importances_gbc[indices_gbc[:3]]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Top 5 Feature Importances\")\n",
    "plt.barh(range(top_n), top_feature_importances[::-1], align=\"center\")  \n",
    "plt.yticks(range(top_n), top_feature_names[::-1])  \n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=GradientBoostingClassifier(random_state=42), param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Parameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_gb_clf = grid_search.best_estimator_\n",
    "y_pred_best = best_gb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(f'Best Model Accuracy: {accuracy_score(y_test, y_pred_best):.4f}')\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv_scores = cross_val_score(gbc, X, y, cv=5, scoring='accuracy')\n",
    "print(f'Cross-validation Accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4: Neural Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
